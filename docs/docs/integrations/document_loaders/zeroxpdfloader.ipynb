{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ZeroxPDFLoader\n",
    "\n",
    "This notebook provides a quick overview for getting started with `ZeroxPDF` [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all DocumentLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.ZeroxPDFLoader.html).\n",
    "\n",
    "## Overview\n",
    "`ZeroxPDFLoader` is a document loader that leverages the [Zerox](https://github.com/getomni-ai/zerox) library. Zerox converts PDF documents into images, processes them using a vision-capable language model, and generates a structured Markdown representation. This loader allows for asynchronous operations and provides page-level document extraction.\n",
    "\n",
    "### Integration details\n",
    "\n",
    "| Class                                                                                                                                             | Package | Local | Serializable | JS support|\n",
    "|:--------------------------------------------------------------------------------------------------------------------------------------------------| :--- | :---: | :---: |  :---: |\n",
    "| [ZeroxPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.ZeroxPDFLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | ❌ | ❌ | ❌ |\n",
    "   \n",
    "---------   \n",
    "\n",
    "### Loader features\n",
    "\n",
    "|   Source    | Document Lazy Loading | Native Async Support | Extract Images | Extract Tables |\n",
    "|:-----------:| :---: | :---: | :---: |:---: |\n",
    "| ZeroxPDFLoader | ✅ | ❌ | ✅ | ✅  |\n",
    "\n",
    "  \n",
    "\n",
    "## Setup\n",
    "\n",
    "### Credentials\n",
    "Appropriate credentials need to be set up in environment variables. The loader supports number of different models and model providers. See _Usage_ header below to see few examples or [Zerox documentation](https://github.com/getomni-ai/zerox) for a full list of supported models.\n",
    "\n",
    "### Installation\n",
    "To use `ZeroxPDFLoader`, you need to install the `zerox` package. Also make sure to have `langchain-community` installed.\n",
    "\n",
    "```bash\n",
    "pip install zerox langchain-community\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "`ZeroxPDFLoader` enables PDF text extraction using vision-capable language models by converting each page into an image and processing it asynchronously. To use this loader, you need to specify a model and configure any necessary environment variables for Zerox, such as API keys.\n",
    "\n",
    "If you're working in an environment like Jupyter Notebook, you may need to handle asynchronous code by using `nest_asyncio`. You can set this up as follows:\n",
    "\n",
    "```python\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T08:03:54.627525Z",
     "start_time": "2024-12-16T08:03:54.601884Z"
    }
   },
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# use nest_asyncio (only necessary inside of jupyter notebook)\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from patch_langchain_community.document_loaders.pdf import ZeroxPDFLoader\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key =\")\n",
    "file_path = \"./example_data/layout-parser-paper.pdf\"\n",
    "loader = ZeroxPDFLoader(file_path)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T08:04:50.148815Z",
     "start_time": "2024-12-16T08:03:56.024813Z"
    }
   },
   "source": [
    "docs = loader.load()\n",
    "docs[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'author': '', 'creationdate': '2021-06-22T01:27:10+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2021-06-22T01:27:10+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'producer': 'pdfTeX-1.40.21', 'subject': '', 'title': '', 'trapped': 'False', 'source': './example_data/layout-parser-paper.pdf', 'total_pages': 16, 'num_pages': 16, 'page': 0}, page_content='# LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis\\n\\nZejian Shen¹ (✉), Ruosen Zhang², Melissa Dell³, Benjamin Charles Germain Lee⁴, Jacob Carlson³, and Weining Li⁵\\n\\n¹ Allen Institute for AI  \\nshannons@allenai.org  \\n² Brown University  \\nruosen_zhang@brown.edu  \\n³ Harvard University  \\n{melissadell, jacob.carlson}@fas.harvard.edu  \\n⁴ University of Washington  \\nbgcl@cs.washington.edu  \\n⁵ University of Waterloo  \\nw4221i@uwaterloo.ca  \\n\\n**Abstract.** Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model configurations complicate the easy reuse of important innovations by a wide audience. Though there have been on-going efforts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applications. The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout detection, character recognition, and many other document processing tasks. To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digitization pipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-world use cases. The library is publicly available at [https://layout-parser.github.io](https://layout-parser.github.io).\\n\\n**Keywords:** Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library · Toolkit.\\n\\n## 1 Introduction\\n\\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classification [11]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T08:04:50.244606Z",
     "start_time": "2024-12-16T08:04:50.239825Z"
    }
   },
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(docs[0].metadata)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': '',\n",
      " 'creationdate': '2021-06-22T01:27:10+00:00',\n",
      " 'creator': 'LaTeX with hyperref',\n",
      " 'keywords': '',\n",
      " 'moddate': '2021-06-22T01:27:10+00:00',\n",
      " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live '\n",
      "                    '2020) kpathsea version 6.3.2',\n",
      " 'producer': 'pdfTeX-1.40.21',\n",
      " 'subject': '',\n",
      " 'title': '',\n",
      " 'trapped': 'False',\n",
      " 'source': './example_data/layout-parser-paper.pdf',\n",
      " 'total_pages': 16,\n",
      " 'num_pages': 16,\n",
      " 'page': 0}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T07:46:59.781582Z",
     "start_time": "2024-12-13T07:46:17.160126Z"
    }
   },
   "outputs": [],
   "source": [
    "pages = []\n",
    "for doc in loader.lazy_load():\n",
    "    pages.append(doc)\n",
    "    if len(pages) >= 10:\n",
    "        # do some paged operation, e.g.\n",
    "        # index.upsert(page)\n",
    "\n",
    "        pages = []\n",
    "len(pages)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(pages[0].page_content[:100])\n",
    "pprint.pp(pages[0].metadata)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The metadata attribute contains at least the following keys:\n",
    "- source\n",
    "- page (if in mode *page*)\n",
    "- total_page\n",
    "- creationdate\n",
    "- creator\n",
    "- producer\n",
    "\n",
    "Additional metadata are specific to each parser.\n",
    "These pieces of information can be helpful (to categorize your PDFs for example)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Splitting mode & custom pages delimiter"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When loading the PDF file you can split it in two different ways:\n",
    "- By page\n",
    "- As a single text flow\n",
    "\n",
    "By default ZeroxPDFLoader will split the PDF by page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Extract the PDF by page. Each page is extracted as a langchain Document object:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loader = ZeroxPDFLoader(\n",
    "    \"./example_data/layout-parser-paper.pdf\",\n",
    "    mode=\"page\",\n",
    ")\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this mode the pdf is split by pages and the resulting Documents metadata contains the page number. But in some cases we could want to process the pdf as a single text flow (so we don't cut some paragraphs in half). In this case you can use the *single* mode :"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Extract the whole PDF as a single langchain Document object:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T15:13:05.016680Z",
     "start_time": "2024-12-11T15:13:04.739002Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = ZeroxPDFLoader(\n",
    "    \"./example_data/layout-parser-paper.pdf\",\n",
    "    mode=\"single\",\n",
    ")\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Logically, in this mode, the ‘page_number’ metadata disappears. Here's how to clearly identify where pages end in the text flow :"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Add a custom *pages_delimitor* to identify where are ends of pages in *single* mode:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T15:13:05.412714Z",
     "start_time": "2024-12-11T15:13:05.034893Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = ZeroxPDFLoader(\n",
    "    \"./example_data/layout-parser-paper.pdf\",\n",
    "    mode=\"single\",\n",
    "    pages_delimitor=\"\\n-------THIS IS A CUSTOM END OF PAGE-------\\n\",\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs[0].page_content[:5780])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This could simply be \\n, or \\f to clearly indicate a page change, or \\<!-- PAGE BREAK --> for seamless injection in a Markdown viewer without a visual effect."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Extract images from the PDF"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "ZeroxPDFLoader is able to extract images from your PDFs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T15:13:41.254995Z",
     "start_time": "2024-12-11T15:13:06.693829Z"
    }
   },
   "outputs": [],
   "source": [
    "from patch_langchain_community.document_loaders.parsers.pdf import (\n",
    "    convert_images_to_description,\n",
    ")\n",
    "\n",
    "loader = ZeroxPDFLoader(\n",
    "    \"./example_data/layout-parser-paper.pdf\",\n",
    "    mode=\"page\",\n",
    "    extract_images=True,\n",
    "    images_to_text=convert_images_to_description(model=None, format=\"html\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[5].page_content)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Working with Files\n",
    "\n",
    "Many document loaders involve parsing files. The difference between such loaders usually stems from how the file is parsed, rather than how the file is loaded. For example, you can use `open` to read the binary content of either a PDF or a markdown file, but you need different parsing logic to convert that binary data into text.\n",
    "\n",
    "As a result, it can be helpful to decouple the parsing logic from the loading logic, which makes it easier to re-use a given parser regardless of how the data was loaded.\n",
    "You can use this strategy to analyze different files, with the same parsing parameters."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T08:06:44.721141Z",
     "start_time": "2024-12-16T08:06:00.565285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from patch_langchain_community.document_loaders.parsers import ZeroxPDFParser\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=\"./example_data/\",\n",
    "        glob=\"*.pdf\",\n",
    "    ),\n",
    "    blob_parser=ZeroxPDFParser(),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs[0].page_content)\n",
    "pprint.pp(docs[0].metadata)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis\n",
      "\n",
      "Zejing Shen¹ (✉), Ruochen Zhang², Melissa Dell³, Benjamin Charles Germain Lee⁴, Jacob Carlson³, and Weining Li⁵\n",
      "\n",
      "¹ Allen Institute for AI  \n",
      "shannons@allenai.org  \n",
      "² Brown University  \n",
      "ruochen_zhang@brown.edu  \n",
      "³ Harvard University  \n",
      "{melissadell, jacob.carlson}@fas.harvard.edu  \n",
      "⁴ University of Washington  \n",
      "bgcl@cs.washington.edu  \n",
      "⁵ University of Waterloo  \n",
      "w422ii@uwaterloo.ca  \n",
      "\n",
      "## Abstract\n",
      "Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model configurations complicate the easy reuse of important innovations by a wide audience. Though there have been on-going efforts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applications. The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout detection, character recognition, and many other document processing tasks. To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digitization pipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-world use cases. The library is publicly available at [https://layout-parser.github.io](https://layout-parser.github.io).\n",
      "\n",
      "**Keywords:** Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library · Toolkit.\n",
      "\n",
      "## 1 Introduction\n",
      "Deep Learning (DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classification [11]\n",
      "{'author': '',\n",
      " 'creationdate': '2021-06-22T01:27:10+00:00',\n",
      " 'creator': 'LaTeX with hyperref',\n",
      " 'keywords': '',\n",
      " 'moddate': '2021-06-22T01:27:10+00:00',\n",
      " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live '\n",
      "                    '2020) kpathsea version 6.3.2',\n",
      " 'producer': 'pdfTeX-1.40.21',\n",
      " 'subject': '',\n",
      " 'title': '',\n",
      " 'trapped': 'False',\n",
      " 'source': 'example_data/layout-parser-paper.pdf',\n",
      " 'total_pages': 16,\n",
      " 'num_pages': 16,\n",
      " 'page': 0}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is possible to work with files from cloud storage."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_community.document_loaders import CloudBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=CloudBlobLoader(\n",
    "        url=\"s3:/mybucket\",  # Supports s3://, az://, gs://, file:// schemes.\n",
    "        glob=\"*.pdf\",\n",
    "    ),\n",
    "    blob_parser=ZeroxPDFParser(),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs[0].page_content)\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "### `ZeroxPDFLoader`\n",
    "\n",
    "This loader class initializes with a file path and model type, and supports custom configurations via `zerox_kwargs` for handling Zerox-specific parameters.\n",
    "\n",
    "**Arguments**:\n",
    "- `file_path` (Union[str, Path]): Path to the PDF file.\n",
    "- `model` (str): Vision-capable model to use for processing in format `<provider>/<model>`.\n",
    "Some examples of valid values are: \n",
    "  - `model = \"gpt-4o-mini\" ## openai model`\n",
    "  - `model = \"azure/gpt-4o-mini\"`\n",
    "  - `model = \"gemini/gpt-4o-mini\"`\n",
    "  - `model=\"claude-3-opus-20240229\"`\n",
    "  - `model = \"vertex_ai/gemini-1.5-flash-001\"`\n",
    "  - See more details in [Zerox documentation](https://github.com/getomni-ai/zerox)\n",
    "  - Defaults to `\"gpt-4o-mini\".`\n",
    "- `**zerox_kwargs` (dict): Additional Zerox-specific parameters such as API key, endpoint, etc.\n",
    "  - See [Zerox documentation](https://github.com/getomni-ai/zerox)\n",
    "\n",
    "**Methods**:\n",
    "- `lazy_load`: Generates an iterator of `Document` instances, each representing a page of the PDF, along with metadata including page number and source.\n",
    "\n",
    "See full API documentaton [here](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.ZeroxPDFLoader.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- **Model Compatibility**: Zerox supports a range of vision-capable models. Refer to [Zerox's GitHub documentation](https://github.com/getomni-ai/zerox) for a list of supported models and configuration details.\n",
    "- **Environment Variables**: Make sure to set required environment variables, such as `API_KEY` or endpoint details, as specified in the Zerox documentation.\n",
    "- **Asynchronous Processing**: If you encounter errors related to event loops in Jupyter Notebooks, you may need to apply `nest_asyncio` as shown in the setup section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "- **RuntimeError: This event loop is already running**: Use `nest_asyncio.apply()` to prevent asynchronous loop conflicts in environments like Jupyter.\n",
    "- **Configuration Errors**: Verify that the `zerox_kwargs` match the expected arguments for your chosen model and that all necessary environment variables are set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "- **Zerox Documentation**: [Zerox GitHub Repository](https://github.com/getomni-ai/zerox)\n",
    "- **LangChain Document Loaders**: [LangChain Documentation](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patch-langchain",
   "language": "python",
   "name": "patch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
